{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph and entropy computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import scripts.boolean_helper\n",
    "from scripts.grid_class import GridParms\n",
    "from scripts.tree_class import Tree, plotReactionGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"pancreatic_cancer\"\n",
    "model_name = \"apoptosis\"\n",
    "seed = 42 # parameter for graph plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaction_system = scripts.boolean_helper.convertRulesToReactions(\"scripts/models/boolean_rulefiles/{}.hpp\".format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_dict = {species_name: i for i, species_name in enumerate(reaction_system.species_names)}\n",
    "sort_key = lambda x: species_dict[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counterEntryToPartitionString(counter_entry):\n",
    "    p = \" \".join((str(species_dict[species_name]) for species_name in counter_entry))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printStats(S, S0, S1, S_sorted, S0_sorted, S1_sorted):\n",
    "    p = \"(({})({}))(({})({}))\".format(\n",
    "        counterEntryToPartitionString(S0_sorted[0]),\n",
    "        counterEntryToPartitionString(S0_sorted[1]),\n",
    "        counterEntryToPartitionString(S1_sorted[0]),\n",
    "        counterEntryToPartitionString(S1_sorted[1]))\n",
    "\n",
    "    print(p)\n",
    "\n",
    "    S_stats = [stat for stat in S[S_sorted].values()]\n",
    "    S0_stats = [stat for stat in S0[S0_sorted].values()]\n",
    "    S1_stats = [stat for stat in S1[S1_sorted].values()]\n",
    "\n",
    "    print(\"\"\"\n",
    "        entropy_root:\\t{:.3f},\\tcount_root:\\t{},\\tcuts_root:\\t{}\n",
    "        entropy_child0:\\t{:.3f},\\tcount_child0:\\t{},\\tcuts_child0:\\t{}\n",
    "        entropy_child1:\\t{:.3f},\\tcount_child1:\\t{},\\tcuts_child1:\\t{}\"\"\".format(*iter(S_stats), *iter(S0_stats), *iter(S1_stats)))\n",
    "    \n",
    "    print(\"\"\"\n",
    "        TOTAL\n",
    "        -----\n",
    "        entropy:\\t{:.3f},\\tcuts:\\t{}\"\"\".format(S_stats[0]+S0_stats[0]+S1_stats[0],\n",
    "                                           S_stats[2]+S0_stats[2]+S1_stats[2]))\n",
    "    \n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernighanLinCounter(G: nx.Graph, n=10000):\n",
    "    partitions = [None] * n\n",
    "    for i in range(n):\n",
    "        bisection = nx.algorithms.community.kernighan_lin_bisection(G, max_iter=2**32)\n",
    "        b0 = tuple(sorted(bisection[0], key=sort_key))\n",
    "        b1 = tuple(sorted(bisection[1], key=sort_key))\n",
    "        if species_dict[b0[0]] < species_dict[b1[0]]:\n",
    "            partitions[i] = (b0, b1)\n",
    "        else:\n",
    "            partitions[i] = (b1, b0)\n",
    "\n",
    "    counter = collections.Counter(partitions)\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = reaction_system.d()\n",
    "n = 2 * np.ones(d, dtype=int)\n",
    "binsize = np.ones(d, dtype=int)\n",
    "liml = np.zeros(d)\n",
    "grid = GridParms(n, binsize, liml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len0 = int(np.floor(reaction_system.d() / 2))\n",
    "nrange = tuple(i for i in range(reaction_system.d()))\n",
    "partition = \"{}{}\".format(nrange[:len0], nrange[len0:]).replace(\",\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = reaction_system.d()\n",
    "n = 2 * np.ones(d, dtype=int)\n",
    "binsize = np.ones(d, dtype=int)\n",
    "liml = np.zeros(d)\n",
    "grid = GridParms(n, binsize, liml)\n",
    "\n",
    "tree = Tree(partition, grid)\n",
    "r_out = np.ones(tree.n_internal_nodes, dtype=\"int\") * 5\n",
    "tree.initialize(reaction_system, r_out)\n",
    "\n",
    "counter = kernighanLinCounter(tree.G)\n",
    "most_common = counter.most_common()\n",
    "\n",
    "print(\"total number of partitions found:\", len(most_common))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = {}\n",
    "for i, (partition, count) in enumerate(most_common):\n",
    "    p = \"({})({})\".format(counterEntryToPartitionString(partition[0]), counterEntryToPartitionString(partition[1]))\n",
    "    tree = Tree(p, grid)\n",
    "    r_out = np.ones(tree.n_internal_nodes, dtype=\"int\") * 5\n",
    "    tree.initialize(reaction_system, r_out)\n",
    "    \n",
    "    entropy = tree.calculateEntropy(tree.root)\n",
    "    cuts = nx.cut_size(tree.G, partition[0], partition[1])\n",
    "    S[partition] = {\"entropy\": entropy, \"count\": count, \"cuts\": cuts}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best subpartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_entropy_sorted = sorted(S, key=lambda x: S[x][\"entropy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Left subpartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G0_entropy = nx.subgraph(tree.G, S_entropy_sorted[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = kernighanLinCounter(G0_entropy)\n",
    "most_common = counter.most_common()\n",
    "p1 = counterEntryToPartitionString(S_entropy_sorted[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S0_entropy = {}\n",
    "for i, (partition, count) in enumerate(most_common):\n",
    "    p00 = counterEntryToPartitionString(partition[0])\n",
    "    p01 = counterEntryToPartitionString(partition[1])\n",
    "    p = \"(({})({}))({})\".format(p00, p01, p1)\n",
    "    tree = Tree(p, grid)\n",
    "    r_out = np.ones(tree.n_internal_nodes, dtype=\"int\") * 5\n",
    "    tree.initialize(reaction_system, r_out)\n",
    "\n",
    "    entropy = tree.calculateEntropy(tree.root.child[0])\n",
    "\n",
    "    cuts = nx.cut_size(G0_entropy, partition[0], partition[1])\n",
    "    S0_entropy[partition] = {\"entropy\": entropy, \"count\": count, \"cuts\": cuts}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Right subpartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_entropy = nx.subgraph(tree.G, S_entropy_sorted[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = kernighanLinCounter(G1_entropy)\n",
    "most_common = counter.most_common()\n",
    "p0 = counterEntryToPartitionString(S_entropy_sorted[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1_entropy = {}\n",
    "for i, (partition, count) in enumerate(most_common):\n",
    "    p10 = counterEntryToPartitionString(partition[0])\n",
    "    p11 = counterEntryToPartitionString(partition[1])\n",
    "    p = \"({})(({})({}))\".format(p0, p10, p11)\n",
    "\n",
    "    tree = Tree(p, grid)\n",
    "    r_out = np.ones(tree.n_internal_nodes, dtype=\"int\") * 5\n",
    "    tree.initialize(reaction_system, r_out)\n",
    "\n",
    "    entropy = tree.calculateEntropy(tree.root.child[1])\n",
    "\n",
    "    cuts = nx.cut_size(G1_entropy, partition[0], partition[1])\n",
    "    S1_entropy[partition] = {\"entropy\": entropy, \"count\": count, \"cuts\": cuts}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S0_entropy_sorted = sorted(S0_entropy, key=lambda x: S0_entropy[x][\"entropy\"])\n",
    "S1_entropy_sorted = sorted(S1_entropy, key=lambda x: S1_entropy[x][\"entropy\"])\n",
    "\n",
    "print(\"best partition (entropy):\")\n",
    "p_best_entropy = printStats(S, S0_entropy, S1_entropy, S_entropy_sorted[0], S0_entropy_sorted[0], S1_entropy_sorted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = Tree(p_best_entropy, grid)\n",
    "r_out = np.ones(tree.n_internal_nodes, dtype=\"int\") * 5\n",
    "tree.initialize(reaction_system, r_out)\n",
    "fig, ax = plotReactionGraph(tree.G, seed=seed)\n",
    "ax.set_title(\"best entropy\");\n",
    "plt.savefig(\"plots/{}_graph_best_entropy.pdf\".format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_count_sorted = sorted(S, key=lambda x: -S[x][\"count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Left subpartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G0_count = nx.subgraph(tree.G, S_count_sorted[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = kernighanLinCounter(G0_count)\n",
    "most_common = counter.most_common()\n",
    "p1 = counterEntryToPartitionString(S_count_sorted[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S0_count = {}\n",
    "for i, (partition, count) in enumerate(most_common):\n",
    "    p00 = counterEntryToPartitionString(partition[0])\n",
    "    p01 = counterEntryToPartitionString(partition[1])\n",
    "    p = \"(({})({}))({})\".format(p00, p01, p1)\n",
    "\n",
    "    tree = Tree(p, grid)\n",
    "    r_out = np.ones(tree.n_internal_nodes, dtype=\"int\") * 5\n",
    "    tree.initialize(reaction_system, r_out)\n",
    "\n",
    "    entropy = tree.calculateEntropy(tree.root.child[0])\n",
    "\n",
    "    cuts = nx.cut_size(G0_count, partition[0], partition[1])\n",
    "    S0_count[partition] = {\"entropy\": entropy, \"count\": count, \"cuts\": cuts}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Right subpartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_count = nx.subgraph(tree.G, S_count_sorted[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = kernighanLinCounter(G1_count)\n",
    "most_common = counter.most_common()\n",
    "p0 = counterEntryToPartitionString(S_count_sorted[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1_count = {}\n",
    "for i, (partition, count) in enumerate(most_common):\n",
    "    p10 = counterEntryToPartitionString(partition[0])\n",
    "    p11 = counterEntryToPartitionString(partition[1])\n",
    "    p = \"({})(({})({}))\".format(p0, p10, p11)\n",
    "\n",
    "    tree = Tree(p, grid)\n",
    "    r_out = np.ones(tree.n_internal_nodes, dtype=\"int\") * 5\n",
    "    tree.initialize(reaction_system, r_out)\n",
    "\n",
    "    entropy = tree.calculateEntropy(tree.root.child[1])\n",
    "\n",
    "    cuts = nx.cut_size(G1_count, partition[0], partition[1])\n",
    "    S1_count[partition] = {\"entropy\": entropy, \"count\": count, \"cuts\": cuts}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S0_count_sorted = sorted(S0_count, key=lambda x: -S0_count[x][\"count\"])\n",
    "S1_count_sorted = sorted(S1_count, key=lambda x: -S1_count[x][\"count\"])\n",
    "\n",
    "print(\"best partition (count):\")\n",
    "p_best_counts = printStats(S, S0_count, S1_count, S_count_sorted[0], S0_count_sorted[0], S1_count_sorted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = Tree(p_best_counts, grid)\n",
    "r_out = np.ones(tree.n_internal_nodes, dtype=\"int\") * 5\n",
    "tree.initialize(reaction_system, r_out)\n",
    "fig, ax = plotReactionGraph(tree.G, seed=seed)\n",
    "ax.set_title(\"best counts\");\n",
    "plt.savefig(\"plots/{}_graph_best_counts.pdf\".format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find worst subpartition (by entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Left subpartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G0_entropy_worst = nx.subgraph(tree.G, S_entropy_sorted[-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = kernighanLinCounter(G0_entropy_worst)\n",
    "most_common = counter.most_common()\n",
    "p1 = counterEntryToPartitionString(S_entropy_sorted[-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S0_entropy_worst = {}\n",
    "for i, (partition, count) in enumerate(most_common):\n",
    "    p00 = counterEntryToPartitionString(partition[0])\n",
    "    p01 = counterEntryToPartitionString(partition[1])\n",
    "    p = \"(({})({}))({})\".format(p00, p01, p1)\n",
    "\n",
    "    tree = Tree(p, grid)\n",
    "    r_out = np.ones(tree.n_internal_nodes, dtype=\"int\") * 5\n",
    "    tree.initialize(reaction_system, r_out)\n",
    "\n",
    "    entropy = tree.calculateEntropy(tree.root.child[0])\n",
    "\n",
    "    cuts = nx.cut_size(G0_entropy_worst, partition[0], partition[1])\n",
    "    S0_entropy_worst[partition] = {\"entropy\": entropy, \"count\": count, \"cuts\": cuts}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Right subpartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_entropy_worst = nx.subgraph(tree.G, S_entropy_sorted[-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = kernighanLinCounter(G1_entropy_worst)\n",
    "most_common = counter.most_common()\n",
    "p0 = counterEntryToPartitionString(S_entropy_sorted[-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1_entropy_worst = {}\n",
    "for i, (partition, count) in enumerate(most_common):\n",
    "    p10 = counterEntryToPartitionString(partition[0])\n",
    "    p11 = counterEntryToPartitionString(partition[1])\n",
    "    p = \"({})(({})({}))\".format(p0, p10, p11)\n",
    "\n",
    "    tree = Tree(p, grid)\n",
    "    r_out = np.ones(tree.n_internal_nodes, dtype=\"int\") * 5\n",
    "    tree.initialize(reaction_system, r_out)\n",
    "\n",
    "    entropy = tree.calculateEntropy(tree.root.child[1])\n",
    "\n",
    "    cuts = nx.cut_size(G1_entropy_worst, partition[0], partition[1])\n",
    "    S1_entropy_worst[partition] = {\"entropy\": entropy, \"count\": count, \"cuts\": cuts}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S0_entropy_worst_sorted = sorted(S0_entropy_worst, key=lambda x: S0_entropy_worst[x][\"entropy\"])\n",
    "S1_entropy_worst_sorted = sorted(S1_entropy_worst, key=lambda x: S1_entropy_worst[x][\"entropy\"])\n",
    "\n",
    "print(\"worst partition (entropy):\")\n",
    "p_worst_entropy = printStats(S, S0_entropy_worst, S1_entropy_worst, S_entropy_sorted[-1], S0_entropy_worst_sorted[-1], S1_entropy_worst_sorted[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = Tree(p_worst_entropy, grid)\n",
    "r_out = np.ones(tree.n_internal_nodes, dtype=\"int\") * 5\n",
    "tree.initialize(reaction_system, r_out)\n",
    "fig, ax = plotReactionGraph(tree.G, seed=seed)\n",
    "ax.set_title(\"worst entropy\");\n",
    "plt.savefig(\"plots/{}_graph_worst_entropy.pdf\".format(model_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
